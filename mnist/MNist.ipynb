{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to install all these dependencies\n",
    "pip/pip3 install keras\n",
    "pip/pip3 install matplotlib\n",
    "pip/pip3 install numpy\n",
    "pip/pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plot\n",
    "import numpy as np\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the mnist data set and ensure the data is shaped properly.\n",
    "The original data is a (28, 28) pixel greyscale image. We need to flatten it for the network.\n",
    "Need a 1 dimensional array for the input (784, ) and a 1 dimensional array for the output (10,) but we have 60,000 data points. So we end up with (60000, 784) and (60000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to show you what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot.imshow(x_train[0].reshape(28, 28), cmap='gray')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a fully connected feed forward neural network - \"Sequential\" makes it feed forward, \"Dense\" makes it fully connected.\n",
    "\n",
    "We're using a relu (rectified linear units)[https://en.wikipedia.org/wiki/Rectifier_(neural_networks)] activation in the hidden layer - it's often recommended for hidden layers in image based problems - not sure why :P\n",
    "\n",
    "We're using softmax in the final layer - it's similar to relu. For some reason, if you replace softmax with relu then the loss will be nan most of the time - not sure why\n",
    "\n",
    "Categorical Crossentropy [https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/] is used as the loss function. I think it's the de-facto loss function for categorisation problems. MSE is used in linear regression but is not suitable for categorisation\n",
    "\n",
    "The optimizer is RMSProp - Stochastic Gradient Descent caused problems for some reason\n",
    "\n",
    "Accuracy is added as a metric - it is simply the percentage of the training set that it guesses correctly. A random guesser we would expect to get 0.1 accuracy. A human, close to 1 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"RMSProp\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 5.7192 - acc: 0.6370\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 3.6193 - acc: 0.7702\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 3.2704 - acc: 0.7934\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 3.1258 - acc: 0.8029\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 3.0208 - acc: 0.8097\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 3.0040 - acc: 0.8111\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 2.9351 - acc: 0.8157\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 2.8830 - acc: 0.8190\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 2.8289 - acc: 0.8223\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 2.7951 - acc: 0.8246\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 2.8286 - acc: 0.8225\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 2.7241 - acc: 0.8291\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 2.7134 - acc: 0.8299\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 2.6588 - acc: 0.8334\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 2.6715 - acc: 0.8328: \n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 2.6760 - acc: 0.8325\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 2.6413 - acc: 0.8347\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 2.6593 - acc: 0.8335\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 2.5961 - acc: 0.8376\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 2.6055 - acc: 0.8372\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 2.5872 - acc: 0.8381\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 2.5808 - acc: 0.8386\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 2.5773 - acc: 0.8389\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 2.5473 - acc: 0.8408\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 2.5701 - acc: 0.8395\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 2.5376 - acc: 0.8412\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 2.5578 - acc: 0.8400\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 2.5637 - acc: 0.8397\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 2.5184 - acc: 0.8427\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 2.1495 - acc: 0.8652\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.8642 - acc: 0.9450\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.8647 - acc: 0.9449\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.8221 - acc: 0.9477\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.8280 - acc: 0.9473\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.8136 - acc: 0.9484: 0s - loss: 0.8132 - acc: \n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.7754 - acc: 0.9507\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.7940 - acc: 0.9495\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.7967 - acc: 0.9495\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.7963 - acc: 0.9496\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.7593 - acc: 0.9517\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.7384 - acc: 0.9531\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.7379 - acc: 0.9532\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.7866 - acc: 0.9503\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.7552 - acc: 0.9521\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.7322 - acc: 0.9536\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.7272 - acc: 0.9539\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.7724 - acc: 0.9512\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.7344 - acc: 0.9535\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.7245 - acc: 0.9541\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.7003 - acc: 0.9558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11c464780>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the model against test data. If the accuracy and loss here are dramatically different to the training data, then we know that our model has overfitted to the training data and will not be useful in real world applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 36us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.89404272279227148, 0.94369999999999998]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a demonstration of the predictive abilities of the trained network - highlight it and hit ctrl+enter to run it against a new random member from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  2\n",
      "--------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADlxJREFUeJzt3XGMlPWdx/HPV4XECEY8chuwHFSCl6AYazZ6iag9ehKFImCMqVGz5sitxm5ylcaInOaIxlgvthdMDIZa7NZQ6SWKQtVre9jUupzNrsq5gAdscUlBBBFMKYRU5Ht/7LOXre78ZnbmmXlm+b5fyWZnn+88z/PNEz48zzO/mfmZuwtAPGcU3QCAYhB+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBndXInZkZbycE6szdrZLn1XTmN7PrzWyHmfWZ2bJatgWgsaza9/ab2ZmSdkq6TtJeSd2SbnX37Yl1OPMDddaIM/8Vkvrcfbe7/1nSOkkLa9gegAaqJfwXSPrDkL/3Zsv+gpm1m1mPmfXUsC8AOav7C37uvlrSaonLfqCZ1HLm3ydpypC/v5ItAzAK1BL+bkkzzOyrZjZW0rckbcinLQD1VvVlv7ufNLMOSb+QdKakNe6+LbfOANRV1UN9Ve2Me36g7hryJh8AoxfhB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0E1dIpuVGfMmDHJ+syZM6ve9rFjx5L1vr6+qreN5saZHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCqmmc38z6JR2V9Lmkk+7emkdTp5tzzz03WV+6dGmyPn/+/GT98ssvH3FPg44ePZqsr1u3LlnfuHFjsv7KK6+MuCc0Rh5v8vl7dz+Uw3YANBCX/UBQtYbfJf3SzN42s/Y8GgLQGLVe9s92931m9teSfmVm/+vubwx9QvafAv8xAE2mpjO/u+/Lfh+UtF7SFcM8Z7W7t/JiINBcqg6/mZ1jZuMHH0uaK2lrXo0BqK9aLvtbJK03s8Ht/NTd/zOXrgDUnbl743Zm1ridNZG2trZkfc2aNTVt/8MPPyxZO378eE3bnjp1arJ+1lnp88eWLVtK1m6++ebkuv39/ck6hufuVsnzGOoDgiL8QFCEHwiK8ANBEX4gKMIPBMVXdzfArFmzalq/u7s7WV+wYEHJ2scff1zTvq+66qpkfcWKFcn6nDlzStZ6e3uT695xxx3J+ksvvZSsI40zPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTh/Ezhx4kSyftNNNyXrtY7lp3R1dSXr8+bNS9bvvPPOkrWnn346ue7DDz+crB86lP7S6DfffDNZj44zPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExVd3N8DFF1+crJ999tnJek9PT57tNI1du3Yl6xdeeGGyvnz58mT98ccfH3FPpwO+uhtAEuEHgiL8QFCEHwiK8ANBEX4gKMIPBFV2nN/M1kj6pqSD7n5Jtux8ST+TNE1Sv6Rb3P1I2Z0FHefH8FauXJmsd3R0JOvbtm1L1i+99NIR93Q6yHOc/8eSrv/CsmWSNrn7DEmbsr8BjCJlw+/ub0g6/IXFCyV1Zo87JS3KuS8AdVbtPX+Lu+/PHn8kqSWnfgA0SM3f4efunrqXN7N2Se217gdAvqo98x8ws0mSlP0+WOqJ7r7a3VvdvbXKfQGog2rDv0FSW/a4TdLL+bQDoFHKht/Mnpf035L+1sz2mtkSSd+TdJ2Z7ZL0D9nfAEaRsvf87n5ridI3cu4FwUyePLmm9ceNG5dTJzHxDj8gKMIPBEX4gaAIPxAU4QeCIvxAUEzRjcLceOONNa3f29ubUycxceYHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAY5x8Fxo4dm6yP1q+oNqvoG6ZL2rx5c06dxMSZHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYpy/Aa688spkvdzn2ufPn5+sz5o1a8Q9nQ7KTdGNNM78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBU2XF+M1sj6ZuSDrr7JdmyFZL+SdLH2dOWu/ur9Wqy2Z133nnJ+pNPPpmst7a21rT/Y8eOlazt2bOnpm2XU26a7XLHphb3339/sn7kyJGSta6urrzbGXUqOfP/WNL1wyz/d3e/LPsJG3xgtCobfnd/Q9LhBvQCoIFquefvMLP3zGyNmU3IrSMADVFt+FdJmi7pMkn7JX2/1BPNrN3Mesysp8p9AaiDqsLv7gfc/XN3PyXph5KuSDx3tbu3unttr2oByFVV4TezSUP+XCxpaz7tAGiUSob6npf0dUkTzWyvpH+V9HUzu0ySS+qXdFcdewRQB+bujduZWeN2lrMJE0q/prl+/frkuldffXVN+37rrbeS9bvuKv1/79at9b0ou/fee5P1J554oq77Tzl8uPQg1YIFC5LrljvmzczdK5oQgXf4AUERfiAowg8ERfiBoAg/EBThB4Liq7srtGTJkpK1Wofy1q5dm6y3t7cn6ydOnKhp/yl33313sv7YY49Vve2NGzcm68uWLUvWp06dmqw/8sgjJWuvv/56ct1yvd1zzz3J+ieffJKsNwPO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFB/prdCpU6dK1sodw82bNyfrixYtStaLHDN+7bXXkvW5c+dWve0ZM2Yk67t3765625LU0tJSsvbUU08l1128eHGyvnLlymR96dKlyXo98ZFeAEmEHwiK8ANBEX4gKMIPBEX4gaAIPxAUn+evkFnpodNy4/wPPvhgsl7PcfzUV45L0qOPPpqsz5kzJ1nfvn17sn7bbbeVrH3wwQfJdWt14MCBkrW2trbkup9++mmy3tHRkay/++67yfpzzz2XrDcCZ34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCKrs5/nNbIqkn0hqkeSSVrv7SjM7X9LPJE2T1C/pFnc/UmZbIT/PP378+GT9+PHjVfVUiXLfT3/ttdcm6/39/cn69OnTR9rSaeGBBx5I1st9nj/1HQ5dXV1V9TQoz8/zn5T0XXefKenvJH3bzGZKWiZpk7vPkLQp+xvAKFE2/O6+393fyR4flfS+pAskLZTUmT2tU1L662gANJUR3fOb2TRJX5P0O0kt7r4/K32kgdsCAKNExe/tN7Nxkl6Q9B13/+PQ97q7u5e6nzezdknpyeYANFxFZ34zG6OB4K919xezxQfMbFJWnyTp4HDruvtqd29199Y8GgaQj7Lht4FT/I8kve/uPxhS2iBp8KNRbZJezr89APVSyVDfbEm/ldQraXC8a7kG7vv/Q9LfSNqjgaG+w2W2NWqH+p599tmStdtvvz257kMPPZSs79ixI1mfPHlysp4aNrrmmmuS67766qvJ+n333Zes9/X1JeunqzPOSJ83y027nvpa8XIfoy6n0qG+svf87v6mpFIb+8ZImgLQPHiHHxAU4QeCIvxAUIQfCIrwA0ERfiAopujOwQ033JCsr1q1KlmfMmVKsv7ZZ58l693d3SVrnZ2dJWuS9MwzzyTrqI+LLrqoZG3nzp01bZspugEkEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIzzN0C5z+NPnDgxWT958mSyXm6abMTCOD+AJMIPBEX4gaAIPxAU4QeCIvxAUIQfCIpxfuA0wzg/gCTCDwRF+IGgCD8QFOEHgiL8QFCEHwiqbPjNbIqZ/drMtpvZNjP752z5CjPbZ2Zbsp959W8XQF7KvsnHzCZJmuTu75jZeElvS1ok6RZJf3L3JyreGW/yAequ0jf5nFXBhvZL2p89Pmpm70u6oLb2ABRtRPf8ZjZN0tck/S5b1GFm75nZGjObUGKddjPrMbOemjoFkKuK39tvZuMk/UbSo+7+opm1SDokySU9ooFbg38ssw0u+4E6q/Syv6Lwm9kYST+X9At3/8Ew9WmSfu7ul5TZDuEH6iy3D/aYmUn6kaT3hwY/eyFw0GJJW0faJIDiVPJq/2xJv5XUK+lUtni5pFslXaaBy/5+SXdlLw6mtsWZH6izXC/780L4gfrj8/wAkgg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBlf0Cz5wdkrRnyN8Ts2XNqFl7a9a+JHqrVp69Ta30iQ39PP+Xdm7W4+6thTWQ0Ky9NWtfEr1Vq6jeuOwHgiL8QFBFh391wftPadbemrUvid6qVUhvhd7zAyhO0Wd+AAUpJPxmdr2Z7TCzPjNbVkQPpZhZv5n1ZjMPFzrFWDYN2kEz2zpk2flm9isz25X9HnaatIJ6a4qZmxMzSxd67JptxuuGX/ab2ZmSdkq6TtJeSd2SbnX37Q1tpAQz65fU6u6Fjwmb2TWS/iTpJ4OzIZnZv0k67O7fy/7jnODu9zdJbys0wpmb69RbqZml71SBxy7PGa/zUMSZ/wpJfe6+293/LGmdpIUF9NH03P0NSYe/sHihpM7scacG/vE0XInemoK773f3d7LHRyUNzixd6LFL9FWIIsJ/gaQ/DPl7r5prym+X9Esze9vM2otuZhgtQ2ZG+khSS5HNDKPszM2N9IWZpZvm2FUz43XeeMHvy2a7++WSbpD07ezytin5wD1bMw3XrJI0XQPTuO2X9P0im8lmln5B0nfc/Y9Da0Ueu2H6KuS4FRH+fZKmDPn7K9mypuDu+7LfByWt18BtSjM5MDhJavb7YMH9/D93P+Dun7v7KUk/VIHHLptZ+gVJa939xWxx4cduuL6KOm5FhL9b0gwz+6qZjZX0LUkbCujjS8zsnOyFGJnZOZLmqvlmH94gqS173Cbp5QJ7+QvNMnNzqZmlVfCxa7oZr9294T+S5mngFf/fS/qXInoo0deFkv4n+9lWdG+SntfAZeBnGnhtZImkv5K0SdIuSf8l6fwm6u05Dczm/J4GgjapoN5ma+CS/j1JW7KfeUUfu0RfhRw33uEHBMULfkBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgvo/+N2vb8bSARgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_mnist_character = random.choice(x_train)\n",
    "result = np.argmax(model.predict(np.array([random_mnist_character])))\n",
    "print(\"Prediction: \", result)\n",
    "print(\"--------------\")\n",
    "\n",
    "plot.imshow(random_mnist_character.reshape(28,28), cmap='gray')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a bunch of quick comparisons of different optimizers. Lower loss, higher accuracy is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 7.3478 - acc: 0.5398\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 3.1768 - acc: 0.7992\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.8949 - acc: 0.8176\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 2.8092 - acc: 0.8235: 0s - los\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 2.6950 - acc: 0.8312\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 2.6723 - acc: 0.8325\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 2.6247 - acc: 0.8358\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 2.5949 - acc: 0.8376\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 2.5550 - acc: 0.8402\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 2.5317 - acc: 0.8418\n",
      "10000/10000 [==============================] - 0s 23us/step\n",
      "loss:  2.44165601139\n",
      "accuracy:  0.8479\n"
     ]
    }
   ],
   "source": [
    "# Root Mean Square Propagation\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"RMSProp\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", result[0])\n",
    "print(\"accuracy: \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 14.5251 - acc: 0.0988\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 14.5280 - acc: 0.0987\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 14.5280 - acc: 0.0987\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 14.5280 - acc: 0.0987\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 14.5280 - acc: 0.0987\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 14.5280 - acc: 0.0987\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 14.5280 - acc: 0.0987\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 14.5280 - acc: 0.0987\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 14.5280 - acc: 0.0987\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 14.5280 - acc: 0.0987\n",
      "10000/10000 [==============================] - 0s 25us/step\n",
      "loss:  14.5739816513\n",
      "accuracy:  0.0958\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", result[0])\n",
    "print(\"accuracy: \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 9.2531 - acc: 0.4238\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 5.4843 - acc: 0.6572\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 3.2244 - acc: 0.7975\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 2.8642 - acc: 0.8203\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 2.7031 - acc: 0.8305\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 2.6579 - acc: 0.8337\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 2.6764 - acc: 0.8327\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 2.6205 - acc: 0.8363\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 2.2045 - acc: 0.8615\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 1.6162 - acc: 0.8982\n",
      "10000/10000 [==============================] - 0s 27us/step\n",
      "loss:  1.50709001517\n",
      "accuracy:  0.9052\n"
     ]
    }
   ],
   "source": [
    "# Adaptive Moment Estimation\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"Adam\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", result[0])\n",
    "print(\"accuracy: \", result[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
