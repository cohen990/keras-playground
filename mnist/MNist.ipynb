{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to install all these dependencies\n",
    "pip/pip3 install keras\n",
    "pip/pip3 install matplotlib\n",
    "pip/pip3 install numpy\n",
    "pip/pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plot\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the mnist data set and ensure the data is shaped properly.\n",
    "The original data is a (28, 28) pixel greyscale image. We need to flatten it for the network.\n",
    "Need a 1 dimensional array for the input (784, ) and a 1 dimensional array for the output (10,) but we have 60,000 data points. So we end up with (60000, 784) and (60000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to show you what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot.imshow(random.choice(x_train).reshape(28, 28), cmap='gray')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a fully connected feed forward neural network - \"Sequential\" makes it feed forward, \"Dense\" makes it fully connected.\n",
    "\n",
    "We're using a relu (rectified linear units)[https://en.wikipedia.org/wiki/Rectifier_(neural_networks)] activation in the hidden layer - it's often recommended for hidden layers in image based problems - not sure why :P\n",
    "\n",
    "We're using softmax in the final layer - it's similar to relu. For some reason, if you replace softmax with relu then the loss will be nan most of the time - not sure why\n",
    "\n",
    "Categorical Crossentropy [https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/] is used as the loss function. I think it's the de-facto loss function for categorisation problems. MSE is used in linear regression but is not suitable for categorisation\n",
    "\n",
    "The optimizer is RMSProp - Stochastic Gradient Descent caused problems for some reason\n",
    "\n",
    "Accuracy is added as a metric - it is simply the percentage of the training set that it guesses correctly. A random guesser we would expect to get 0.1 accuracy. A human, close to 1 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"RMSProp\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 15s 246us/step - loss: 9.7175 - acc: 0.3947\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 8.6656 - acc: 0.4605\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 7.6207 - acc: 0.5255\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 7.0849 - acc: 0.5592 4s - loss: 7.1746 \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 7.0061 - acc: 0.5644\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 6.9308 - acc: 0.5691 0s - loss: 6.9467 - a\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 6.9263 - acc: 0.5693\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 6.8863 - acc: 0.5720\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 6.8769 - acc: 0.5727\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 6.8238 - acc: 0.5760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1229de9b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the model against test data. If the accuracy and loss here are dramatically different to the training data, then we know that our model has overfitted to the training data and will not be useful in real world applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 58us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.9778738250732424, 0.56569999999999998]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a demonstration of the predictive abilities of the trained network - highlight it and hit ctrl+enter to run it against a new random member from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  4\n",
      "--------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_mnist_character = random.choice(x_train)\n",
    "result = np.argmax(model.predict(np.array([random_mnist_character])))\n",
    "print(\"Prediction: \", result)\n",
    "print(\"--------------\")\n",
    "\n",
    "plot.imshow(random_mnist_character.reshape(28,28), cmap='gray')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a bunch of quick comparisons of different optimizers. Lower loss, higher accuracy is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 7.6771 - acc: 0.5204\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 6.2344 - acc: 0.6113\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 5.5187 - acc: 0.6557\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 4.2440 - acc: 0.7344\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 14s 235us/step - loss: 4.1112 - acc: 0.7430\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 3.5934 - acc: 0.7748\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 15s 252us/step - loss: 2.8359 - acc: 0.8212\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 2.6369 - acc: 0.8344\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 14s 236us/step - loss: 2.6373 - acc: 0.8347\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 2.5512 - acc: 0.8401\n",
      "10000/10000 [==============================] - 2s 153us/step\n",
      "loss:  2.59183896751\n",
      "accuracy:  0.8381\n"
     ]
    }
   ],
   "source": [
    "# Root Mean Square Propagation\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"RMSProp\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", result[0])\n",
    "print(\"accuracy: \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 16s 264us/step - loss: 14.5148 - acc: 0.0995\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 14.5176 - acc: 0.0993\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 14.5176 - acc: 0.0993\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 14.5176 - acc: 0.0993\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 14.5176 - acc: 0.0993\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 14.5176 - acc: 0.0993\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 14.5176 - acc: 0.0993\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 14.5176 - acc: 0.0993\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 15s 245us/step - loss: 14.5176 - acc: 0.0993\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 14.5176 - acc: 0.0993\n",
      "10000/10000 [==============================] - 1s 145us/step\n",
      "loss:  14.454707753\n",
      "accuracy:  0.1032\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", result[0])\n",
    "print(\"accuracy: \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 10.6221 - acc: 0.3398\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 10.2030 - acc: 0.3664\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 10.1498 - acc: 0.3698\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 10.0202 - acc: 0.3780\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 9.9873 - acc: 0.3801\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 10.0039 - acc: 0.3791\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 9.9767 - acc: 0.3808\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 9.9871 - acc: 0.3802\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 9.9852 - acc: 0.3804\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 9.9593 - acc: 0.3819 1s - loss: 9.9699 - acc: 0.38 - ETA: 1s - loss: 9.9696 \n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "loss:  10.1267960815\n",
      "accuracy:  0.3716\n"
     ]
    }
   ],
   "source": [
    "# Adaptive Moment Estimation\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"Adam\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", result[0])\n",
    "print(\"accuracy: \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.1658 - acc: 0.1705\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.1626 - acc: 0.1868\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.1612 - acc: 0.1933\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.1551 - acc: 0.2243\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.1496 - acc: 0.2518\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 15s 247us/step - loss: 0.1503 - acc: 0.2482\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 0.1491 - acc: 0.2544\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 0.1467 - acc: 0.2661\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1471 - acc: 0.2643\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 0.1464 - acc: 0.2676\n",
      "10000/10000 [==============================] - 2s 237us/step\n",
      "loss:  0.145912384915\n",
      "accuracy:  0.2702\n"
     ]
    }
   ],
   "source": [
    "# Root Mean Square Propagation with mean squared error\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=\"RMSProp\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", result[0])\n",
    "print(\"accuracy: \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.1366 - acc: 0.3119\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.1144 - acc: 0.4250\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.1110 - acc: 0.4423\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.1108 - acc: 0.4434\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.1092 - acc: 0.4517\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0993 - acc: 0.5005\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.0934 - acc: 0.5305\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0932 - acc: 0.5319\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0919 - acc: 0.5384\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.0914 - acc: 0.5407\n",
      "10000/10000 [==============================] - 1s 117us/step\n",
      "loss:  0.0926221408248\n",
      "accuracy:  0.5348\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent with mean squared error\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", result[0])\n",
    "print(\"accuracy: \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.1492 - acc: 0.2533\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.1459 - acc: 0.2703\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.1441 - acc: 0.2792\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.1444 - acc: 0.2776\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.1425 - acc: 0.28720s - loss: 0.142\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.1426 - acc: 0.2871\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.1357 - acc: 0.3215\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.1279 - acc: 0.3605\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.1262 - acc: 0.3687\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.1295 - acc: 0.3523: 1s - loss: 0.\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "loss:  0.125024506998\n",
      "accuracy:  0.3748\n"
     ]
    }
   ],
   "source": [
    "# Adaptive Moment Estimation with mean squared error\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=\"Adam\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", result[0])\n",
    "print(\"accuracy: \", result[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
