{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to install all these dependencies\n",
    "pip/pip3 install keras\n",
    "pip/pip3 install matplotlib\n",
    "pip/pip3 install numpy\n",
    "pip/pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plot\n",
    "import numpy as np\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the mnist data set and ensure the data is shaped properly.\n",
    "The original data is a (28, 28) pixel greyscale image. We need to flatten it for the network.\n",
    "Need a 1 dimensional array for the input (784, ) and a 1 dimensional array for the output (10,) but we have 60,000 data points. So we end up with (60000, 784) and (60000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to show you what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot.imshow(x_train[0].reshape(28, 28), cmap='gray')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a fully connected feed forward neural network - \"Sequential\" makes it feed forward, \"Dense\" makes it fully connected.\n",
    "\n",
    "We're using a relu (rectified linear units)[https://en.wikipedia.org/wiki/Rectifier_(neural_networks)] activation in the hidden layer - it's often recommended for hidden layers in image based problems - not sure why :P\n",
    "\n",
    "We're using softmax in the final layer - it's similar to relu. For some reason, if you replace softmax with relu then the loss will be nan most of the time - not sure why\n",
    "\n",
    "Categorical Crossentropy [https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/] is used as the loss function. I think it's the de-facto loss function for categorisation problems. MSE is used in linear regression but is not suitable for categorisation\n",
    "\n",
    "The optimizer is RMSProp - Stochastic Gradient Descent caused problems for some reason\n",
    "\n",
    "Accuracy is added as a metric - it is simply the percentage of the training set that it guesses correctly. A random guesser we would expect to get 0.1 accuracy. A human, close to 1 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"Adam\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 20s 337us/step - loss: 10.4486 - acc: 0.3507\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 15s 245us/step - loss: 9.2087 - acc: 0.4279\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 15s 250us/step - loss: 8.9015 - acc: 0.4470\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 8.7020 - acc: 0.4596\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 8.6468 - acc: 0.46320s - loss: 8.6494 - acc: 0\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 14s 236us/step - loss: 7.6542 - acc: 0.5244\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 14s 235us/step - loss: 7.3192 - acc: 0.5454\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 7.2140 - acc: 0.5520\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 7.1880 - acc: 0.5538\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 14s 225us/step - loss: 7.1334 - acc: 0.5573\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 7.0913 - acc: 0.5598\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 7.1439 - acc: 0.5565\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 14s 229us/step - loss: 7.0786 - acc: 0.5606\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 7.0372 - acc: 0.5631\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 13s 225us/step - loss: 7.0254 - acc: 0.5638\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 7.1321 - acc: 0.5573\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 14s 231us/step - loss: 7.0914 - acc: 0.5599\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 7.0444 - acc: 0.5627\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 7.0155 - acc: 0.5646\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 7.0451 - acc: 0.5627\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 6.9627 - acc: 0.5678\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 6.9381 - acc: 0.5694\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 6.9662 - acc: 0.5676\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 6.9519 - acc: 0.5685\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 6.9666 - acc: 0.5676\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 7.0120 - acc: 0.5647\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 6.9482 - acc: 0.5687\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 6.9327 - acc: 0.5698\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 6.8750 - acc: 0.5733\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 6.9710 - acc: 0.5674\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 6.9478 - acc: 0.5688\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 6.8944 - acc: 0.57210s - loss: 6.9\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 6.9287 - acc: 0.5700\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 14s 228us/step - loss: 6.9544 - acc: 0.5684\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 6.9536 - acc: 0.5684\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 14s 225us/step - loss: 6.9409 - acc: 0.5693\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 6.9006 - acc: 0.5717\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 6.8938 - acc: 0.5721\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 14s 228us/step - loss: 6.8202 - acc: 0.5768\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 6.9434 - acc: 0.5691\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 6.9166 - acc: 0.57071s - lo\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 6.8488 - acc: 0.5750\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 6.9373 - acc: 0.5695\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 6.9447 - acc: 0.5690\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 6.9242 - acc: 0.5703\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 14s 231us/step - loss: 6.9161 - acc: 0.5708\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 6.8814 - acc: 0.5730\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 6.8840 - acc: 0.5728\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 6.9281 - acc: 0.5700\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 6.8726 - acc: 0.5735\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 6.9431 - acc: 0.5691\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 6.8516 - acc: 0.5748\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 6.8343 - acc: 0.5759\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 6.8608 - acc: 0.5742\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 6.8552 - acc: 0.5746\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1808s 30ms/step - loss: 6.8389 - acc: 0.5756\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 23s 389us/step - loss: 6.9102 - acc: 0.5711\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 18s 308us/step - loss: 6.8328 - acc: 0.5759\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 18s 306us/step - loss: 6.8181 - acc: 0.5769\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 19s 311us/step - loss: 6.9306 - acc: 0.5699\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 6.8404 - acc: 0.5754\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 18s 308us/step - loss: 6.8164 - acc: 0.5771\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2098s 35ms/step - loss: 6.7865 - acc: 0.5789\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 6.8415 - acc: 0.5754\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 6.8588 - acc: 0.5744\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1061s 18ms/step - loss: 6.8173 - acc: 0.57709s - loss: 6.8214\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 6.8342 - acc: 0.5759\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 6.9186 - acc: 0.5707\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 6.8677 - acc: 0.5738\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 6.8218 - acc: 0.5766\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 6.7640 - acc: 0.5803\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 6.8126 - acc: 0.5772\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 6.7618 - acc: 0.5804\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 14s 228us/step - loss: 6.7873 - acc: 0.5789\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 6.8089 - acc: 0.5775\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 14s 236us/step - loss: 6.9214 - acc: 0.5705\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 6.9223 - acc: 0.5704\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 17s 291us/step - loss: 6.7896 - acc: 0.5787\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 13s 218us/step - loss: 6.7468 - acc: 0.5813\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 13s 225us/step - loss: 6.6444 - acc: 0.5876\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 5.7528 - acc: 0.6430\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 15s 255us/step - loss: 5.5553 - acc: 0.6551\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 5.4993 - acc: 0.6586\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 14s 236us/step - loss: 5.4179 - acc: 0.6637\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 14s 231us/step - loss: 5.3556 - acc: 0.6676\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 5.4354 - acc: 0.6627\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 15s 247us/step - loss: 5.3279 - acc: 0.6693\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 5.3396 - acc: 0.6686\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 14s 238us/step - loss: 5.3188 - acc: 0.6699\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 14s 236us/step - loss: 5.3146 - acc: 0.6701\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 5.3439 - acc: 0.6683\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 5.3286 - acc: 0.6693\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 5.4207 - acc: 0.6636\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 5.3120 - acc: 0.6703\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 5.3280 - acc: 0.6693\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 5.2517 - acc: 0.6741\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 5.2786 - acc: 0.6724\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 5.2669 - acc: 0.6731\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 5.2985 - acc: 0.6711\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 5.2656 - acc: 0.6732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x106fb3e10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the model against test data. If the accuracy and loss here are dramatically different to the training data, then we know that our model has overfitted to the training data and will not be useful in real world applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 90us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.2770789535522464, 0.67249999999999999]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a demonstration of the predictive abilities of the trained network - highlight it and hit ctrl+enter to run it against a new random member from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  5\n",
      "--------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_mnist_character = random.choice(x_train)\n",
    "result = np.argmax(model.predict(np.array([random_mnist_character])))\n",
    "print(\"Prediction: \", result)\n",
    "print(\"--------------\")\n",
    "\n",
    "plot.imshow(random_mnist_character.reshape(28,28), cmap='gray')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a bunch of quick comparisons of different optimizers. Lower loss, higher accuracy is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 9.6918 - acc: 0.3963\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 7.1460 - acc: 0.5549\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 7.0025 - acc: 0.5642\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 6.9437 - acc: 0.5680\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 6.8591 - acc: 0.5734\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 6.8346 - acc: 0.5750\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 6.7897 - acc: 0.5780\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 6.7977 - acc: 0.5774\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 6.7291 - acc: 0.5817\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 6.7246 - acc: 0.5819\n",
      "10000/10000 [==============================] - 1s 108us/step\n",
      "loss:  6.65426273804\n",
      "accuracy:  0.5868\n"
     ]
    }
   ],
   "source": [
    "# Root Mean Square Propagation\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"RMSProp\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", result[0])\n",
    "print(\"accuracy: \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 13.7503 - acc: 0.1468\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 13.3097 - acc: 0.1742\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 13.2397 - acc: 0.1786\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 13.3016 - acc: 0.1747\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 13.5371 - acc: 0.1601\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 13.2819 - acc: 0.1759\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 13.2061 - acc: 0.1807\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 13.6026 - acc: 0.1560\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 13.6476 - acc: 0.1533\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 14.0802 - acc: 0.1264\n",
      "10000/10000 [==============================] - 1s 81us/step\n",
      "loss:  14.0423183701\n",
      "accuracy:  0.1287\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", result[0])\n",
    "print(\"accuracy: \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 6.0552 - acc: 0.6187\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 4.6836 - acc: 0.7066\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 3.7277 - acc: 0.7656\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 2.9282 - acc: 0.8163\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 2.8776 - acc: 0.8194\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 2.8187 - acc: 0.8236\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 2.8173 - acc: 0.8236\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 2.7111 - acc: 0.8306\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 2.7452 - acc: 0.8286\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 2.7143 - acc: 0.8305\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "loss:  2.60097916279\n",
      "accuracy:  0.8376\n"
     ]
    }
   ],
   "source": [
    "# Adaptive Moment Estimation\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"Adam\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", result[0])\n",
    "print(\"accuracy: \", result[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
